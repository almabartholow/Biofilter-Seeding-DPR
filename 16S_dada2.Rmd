---
title: "16S Analysis"
output: html_notebook
---
# DADA2
## Load Libraries

```{r}
library("dada2")
library("phyloseq")
library("ggplot2")
library("repr")
library("dplyr")
library("tibble")
library("Biostrings")
library("ShortRead")
```


## Read in names

```{r}
path <- "C:/Users/almab/16S" # CHANGE ME to the directory containing the fastq files after unzipping.

setwd(path)
```

```{r}

fnFs <- sort(list.files(path, pattern = "_R1_001.fastq", full.names = TRUE))
fnRs <- sort(list.files(path, pattern = "_R2_001.fastq", full.names = TRUE))  # CHANGE if different file extensions

```


```{r}
sample.names <- sapply(strsplit(basename(fnFs), "_S"), `[`,1)
sample.names
```


## Inspect read quality profiles

```{r}
# Plot quality profiles for forward reads
# Uncomment to inspect different samples/ranges:
# plotQualityProfile(fnFs[1:4])
# plotQualityProfile(fnFs[1]) + xlim(0, 25) + geom_hline(aes(yintercept = 30))  # trimleft 5 first bp
plotQualityProfile(fnFs[4]) + xlim(250, 300) + geom_hline(aes(yintercept = 30))  # trimright 275

# Plot quality profiles for reverse reads
# Uncomment to inspect reverse reads:
# plotQualityProfile(fnRs[1]) + xlim(0, 25) + geom_hline(aes(yintercept = 30))  # trimleft first 5bp
# plotQualityProfile(fnRs[4]) + xlim(150, 250) + geom_hline(aes(yintercept = 30))  # trimright 200? 

```

## Trim and Filtering Reads

```{r}
# Trim and Filtering Reads
#reverse and forward reads
#filterAndTrim(file.path(path,fnFs), file.path(filtpath,fnFs), file.path(path,fnRs), file.path(filtpath,fnRs),
#              truncLen=c(275,200), trimLeft= 5, maxEE=1, truncQ=10, minLen= 200 ,  n = 1e+05, rm.phix=TRUE, compress=TRUE, verbose=TRUE, multithread =FALSE)


```

```{r}

filtFs <- file.path(path, "filtered_new", paste0(sample.names, "_F_filt.fastq.gz"))

names(filtFs) <- sample.names

```


```{r}

# Filter forward reads only (reverse reads too messy)
out <- filterAndTrim(
  fnFs, filtFs,
  truncLen = 250,
  trimLeft = 5,
  maxEE = 1,
  truncQ = 10,
  minLen = 200,
  n = 1e+05,
  rm.phix = TRUE,
  compress = TRUE,
  verbose = TRUE,
  multithread = FALSE
)
```

```{r}
# Define reverse read file paths (if using reverse reads)
filtRs <- file.path(path, "filtered", paste0(sample.names, "_R_filt.fastq.gz"))
names(filtRs) <- sample.names
```

```{r}


# Filter reverse reads (optional - currently using forward reads only)
filterAndTrim(
  fnRs, filtRs,
  compress = TRUE,
  truncQ = 10,
  truncLen = 220,
  trimLeft = 5,
  minLen = 200,
  maxN = 0,
  minQ = 0,
  maxEE = 1,
  rm.phix = TRUE,
  n = 1e+05,
  verbose = TRUE,
  multithread = FALSE
)
```



## Learn the error rates





```{r}

# Learn error rates from forward reads
# Include nbases = 1e9 when doing full set
errF <- learnErrors(filtFs, nbases = 1e9, multithread = TRUE)
```

```{r}
filts <- list.files(file.path(path, "filtered_new"), 
                    pattern = "_F_filt.fastq.gz", 
                    full.names = TRUE)
#sample.names <- sapply(strsplit(basename(fnFs), "_S"), `[`,1)
names(filts) <- sample.names

sample.names
```


```{r}
plotErrors(errF, nominalQ = TRUE)

```




## Sample Inference

```{r}
# Infer sequence variants
dds <- vector("list", length(sample.names))
names(dds) <- sample.names
for(sam in sample.names) {
  cat("Processing:", sam, "\n")
  derep <- derepFastq(filts[[sam]])
  dds[[sam]] <- dada(derep, err = errF, multithread = TRUE)
}
```


## Construct sequence table

```{r}
seqtab <- makeSequenceTable(dds)
saveRDS(seqtab, file.path(path, "subset", "seqtabn1e9.rds"))

```

```{r}
dim(seqtab)
```
## Remove Chimeras
```{r}
seqtab.nochim <- removeBimeraDenovo(
  seqtab,
  method = "consensus",
  multithread = TRUE,
  verbose = TRUE
)
dim(seqtab.nochim)
```

```{r}
sum(seqtab.nochim)/sum(seqtab)

```


```{r}
# Investigate the percent of total reads that were chimeric
reads_filtered <- as.data.frame(rowSums(seqtab))
colnames(reads_filtered) <- "reads_filtered"
reads_nochim <- as.data.frame(rowSums(seqtab.nochim))
colnames(reads_nochim) <- "reads_nochim"
stats <- merge(reads_filtered, reads_nochim, by = 0)
stats$percent_chim <- 100 * (stats$reads_filtered - stats$reads_nochim) / stats$reads_filtered
tail(stats[order(stats$percent_chim), ])
ggplot(stats, aes(x = percent_chim)) +
  geom_histogram(binwidth = 2.5) +
  labs(x = "Percent Chimeric Reads", y = "Number of Samples")
```

## Track Reads through pipeline
```{r}
getN <- function(x) sum(getUniques(x))
track <- cbind(out, sapply(dds, getN), rowSums(seqtab.nochim))
# If processing a single sample, remove the sapply calls: e.g. replace sapply(dadaFs, getN) with getN(dadaFs)
colnames(track) <- c("input", "filtered", "denoisedF", "nonchim")
rownames(track) <- sample.names
head(track)
```

## Assign Taxonomy

**Note:** We explored clustering ASVs into OTUs but ultimately decided to proceed with ASVs (amplicon sequence variants) directly, as they provide higher resolution and avoid arbitrary similarity thresholds.



```{r}
tax <- assignTaxonomy(
  seqtab.nochim,
  file.path(path, "subset", "silva_nr99_v138.1_train_set.fa.gz"),
  multithread = TRUE
)
```


```{r}
taxa.print <- tax # Removing sequence rownames for display only
rownames(taxa.print) <- NULL
head(taxa.print)
```



```{r}
# Write to disk
saveRDS(seqtab.nochim, file.path(path, "seqtab.rds"))
saveRDS(tax, file.path(path, "tax.rds"))
```

## Evaluate Accuracy
```{r}
mock_samples <- c(
  "mock10_082523_1", "mock10_082523_2",
  "mock8_082523_1", "mock8_082523_2",
  "mock6_082523_1", "mock6_082523_2"
)

unqs.mock <- as.data.frame(seqtab.nochim) %>%
  filter(row.names(seqtab.nochim) %in% mock_samples)
unqs.mock <- as.data.frame(lapply(unqs.mock, as.numeric))
unqs.mock <- unqs.mock %>% select_if(colSums(.) > 0)

cat("DADA2 inferred", ncol(unqs.mock),
    "sample sequences present in the Mock community.\n")
```

```{r}
mock.ref <- getSequences(file.path(path, "subset", "ZymoBIOMICS.STD.refseq.v2", "ssrRNAs"))

match.ref <- sum(sapply(names(unqs.mock), function(x) any(grepl(x, mock.ref))))
cat("Of those,", match.ref,
    "were exact matches to the expected reference sequences.\n")
```



## Make Phyloseq object

```{r}
tax <- readRDS(file.path(path, "tax_finaln1e9.rds"))
seqtab.nochim <- readRDS(file.path(path, "seqtab_finaln1e9.rds"))

metadata <- read.csv(file.path(path, "metadata.csv"), header = TRUE, row.names = 1)
```

```{r}
sum(is.na(tax[, "Genus"]))
sum(!is.na(tax[, "Genus"]))
sum(is.na(tax[, "Genus"])) / 
  (sum(!is.na(tax[, "Genus"])) + sum(is.na(tax[, "Genus"])))

```


```{r}
theme_set(theme_bw())

```


```{r}
# Construct a phyloseq object
ps <- phyloseq(
  otu_table(seqtab.nochim, taxa_are_rows = FALSE),
  sample_data(metadata),
  tax_table(tax)
)
# ps <- prune_samples(sample_names(ps) != "Mock", ps)  # Remove mock sample
```




```{r}
# new names
dna <- Biostrings::DNAStringSet(taxa_names(ps))
names(dna) <- taxa_names(ps)
ps <- merge_phyloseq(ps, dna)
taxa_names(ps) <- paste0("ASV", seq(ntaxa(ps)))
ps
```

```{r}
saveRDS(ps, file.path(path, "ps_raw_from_dada2_new.rds"))
```


## Check primers removed


```{r}
allOrients <- function(primer) {
  # Create all orientations of the input sequence
  require(Biostrings)
  dna <- DNAString(primer)  # Biostrings works with DNAString objects
  orients <- c(
    Forward = dna,
    Complement = Biostrings::complement(dna),
    Reverse = Biostrings::reverse(dna),
    RevComp = Biostrings::reverseComplement(dna)
  )
  return(sapply(orients, toString))  # Convert back to character vector
}
```


```{r}
fnFs.filtN <- file.path(path, "filtN", basename(fnFs)) # Put N-filtered files in filtN/ subdirectory
fnRs.filtN <- file.path(path, "filtN", basename(fnRs))
filterAndTrim(fnFs, fnFs.filtN, fnRs, fnRs.filtN, maxN = 0, multithread = TRUE)
```

```{r}
FWD <- "TATGGTAATTGTGTGCCAGCMGCCGCGGTAA"
REV <- "AGTCAGTCAGCCGGACTACHVGGGTWTCTAAT"
```

```{r}
FWD.orients <- allOrients(FWD)
REV.orients <- allOrients(REV)
FWD.orients
```
```{r}
primerHits <- function(primer, fn) {
  # Counts number of reads in which the primer is found
  nhits <- vcountPattern(primer, sread(readFastq(fn)), fixed = FALSE)
  return(sum(nhits > 0))
}
```


```{r}

rbind(
  FWD.ForwardReads = sapply(FWD.orients, primerHits, fn = fnFs.filtN[[1]]),
  FWD.ReverseReads = sapply(FWD.orients, primerHits, fn = fnRs.filtN[[1]]),
  REV.ForwardReads = sapply(REV.orients, primerHits, fn = fnFs.filtN[[1]]),
  REV.ReverseReads = sapply(REV.orients, primerHits, fn = fnRs.filtN[[1]])
)

```


## Plots
```{r}
# Alpha Diversity
plot_richness(ps, x = "Day", measures = c("Shannon", "Simpson"), 
              color = "Sample_type")

# Note: Other measures of diversity that aren't totally reliant on singletons,
# e.g. Shannon/Simpson, are valid to use, and you can ignore the warning in
# phyloseq when calculating those measures.
```

```{r}
# Ordination
# Transform data to proportions as appropriate for Bray-Curtis distances
ps.prop <- transform_sample_counts(ps, function(otu) otu / sum(otu))
ord.nmds.bray <- ordinate(ps.prop, method = "NMDS", distance = "bray")
```

```{r}
plot_ordination(ps.prop, ord.nmds.bray, color = "Sample_type", 
                title = "Bray NMDS")

```

```{r}
# Bar Chart - Top 50 taxa
top50 <- names(sort(taxa_sums(ps), decreasing = TRUE))[1:50]
ps.top50 <- transform_sample_counts(ps, function(OTU) OTU / sum(OTU))
ps.top50 <- prune_taxa(top50, ps.top50)
plot_bar(ps.top50, x = "Day", fill = "Family") + 
  facet_wrap(~Sample_type, scales = "free_x")
```



